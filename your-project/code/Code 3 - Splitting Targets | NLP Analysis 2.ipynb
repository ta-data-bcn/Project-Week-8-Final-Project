{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'../data/personalities_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['I-E'] = data2['type'].astype(str).str[0]\n",
    "data2['N-S'] = data2['type'].astype(str).str[1]\n",
    "data2['T-F'] = data2['type'].astype(str).str[2]\n",
    "data2['J-P'] = data2['type'].astype(str).str[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.drop(columns=['Unnamed: 0', 'posts', 'text_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type          0\n",
       "text_ready    1\n",
       "I-E           0\n",
       "N-S           0\n",
       "T-F           0\n",
       "J-P           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text_ready</th>\n",
       "      <th>I-E</th>\n",
       "      <th>N-S</th>\n",
       "      <th>T-F</th>\n",
       "      <th>J-P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type text_ready I-E N-S T-F J-P\n",
       "3559  INFP        NaN   I   N   F   P"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = data2[data2.isna().any(axis=1)]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(data2.index[3559], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type          0\n",
       "text_ready    0\n",
       "I-E           0\n",
       "N-S           0\n",
       "T-F           0\n",
       "J-P           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text_ready</th>\n",
       "      <th>I-E</th>\n",
       "      <th>N-S</th>\n",
       "      <th>T-F</th>\n",
       "      <th>J-P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>intj moment sportscent top ten play prank ha l...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>find lack post veri alarm sex bore posit often...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one cours say know bless cur doe absolut ...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp enjoy convers day esoter gab natur u...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fire anoth silli misconcept approach logic go ...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                         text_ready I-E N-S T-F J-P\n",
       "0  INFJ  intj moment sportscent top ten play prank ha l...   I   N   F   J\n",
       "1  ENTP  find lack post veri alarm sex bore posit often...   E   N   T   P\n",
       "2  INTP  good one cours say know bless cur doe absolut ...   I   N   T   P\n",
       "3  INTJ  dear intp enjoy convers day esoter gab natur u...   I   N   T   J\n",
       "4  ENTJ  fire anoth silli misconcept approach logic go ...   E   N   T   J"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining learnings for each \n",
    "x = data2['text_ready']\n",
    "\n",
    "y_IE = data2['I-E']\n",
    "y_NS = data2['N-S']\n",
    "y_TF = data2['T-F']\n",
    "y_JP = data2['J-P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for vector functions\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vector = CountVectorizer(ngram_range=(2, 2)).fit(x) \n",
    "X = vector.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "svd = TruncatedSVD(n_components = 100)\n",
    "reduced = svd.fit_transform(X)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I    6675\n",
       "E    1999\n",
       "Name: I-E, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_IE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E Accuracy for  1  neigbours.\n",
      "Label I-E test score is : 0.6789625360230548\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[  99  284]\n",
      " [ 273 1079]]\n",
      "I-E Accuracy for  3  neigbours.\n",
      "Label I-E test score is : 0.7152737752161383\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[  74  335]\n",
      " [ 159 1167]]\n",
      "I-E Accuracy for  5  neigbours.\n",
      "Label I-E test score is : 0.7527377521613833\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[  41  346]\n",
      " [  83 1265]]\n",
      "I-E Accuracy for  7  neigbours.\n",
      "Label I-E test score is : 0.7440922190201729\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[  26  388]\n",
      " [  56 1265]]\n",
      "I-E Accuracy for  9  neigbours.\n",
      "Label I-E test score is : 0.7510086455331412\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[  21  383]\n",
      " [  49 1282]]\n",
      "I-E Accuracy for  11  neigbours.\n",
      "Label I-E test score is : 0.7538904899135447\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[  17  387]\n",
      " [  40 1291]]\n",
      "I-E Accuracy for  13  neigbours.\n",
      "Label I-E test score is : 0.7619596541786744\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   9  393]\n",
      " [  20 1313]]\n",
      "I-E Accuracy for  15  neigbours.\n",
      "Label I-E test score is : 0.7665706051873199\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   6  389]\n",
      " [  16 1324]]\n",
      "I-E Accuracy for  17  neigbours.\n",
      "Label I-E test score is : 0.7631123919308357\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   8  398]\n",
      " [  13 1316]]\n",
      "I-E Accuracy for  19  neigbours.\n",
      "Label I-E test score is : 0.7648414985590778\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   8  400]\n",
      " [   8 1319]]\n",
      "I-E Accuracy for  21  neigbours.\n",
      "Label I-E test score is : 0.7596541786743516\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   6  411]\n",
      " [   6 1312]]\n",
      "I-E Accuracy for  23  neigbours.\n",
      "Label I-E test score is : 0.7636887608069164\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   2  402]\n",
      " [   8 1323]]\n",
      "I-E Accuracy for  25  neigbours.\n",
      "Label I-E test score is : 0.7711815561959654\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   2  393]\n",
      " [   4 1336]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "for x in range(1, 26, 2):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(reduced, y_IE, test_size=0.2)\n",
    "    knn = KNeighborsClassifier(n_neighbors = x)\n",
    "    clf = knn.fit(x_train, y_train)\n",
    "    predknn = clf.predict(x_test)\n",
    "    print(\"I-E Accuracy for \", x, \" neigbours.\")\n",
    "    print('Label I-E test score is :',accuracy_score(y_test, predknn))\n",
    "    print(\"Confusion Matrix for KNeighbors:\")\n",
    "    print(confusion_matrix(y_test, predknn))\n",
    "    #print(\"Score:\",round(accuracy_score(predknn, y_test)*100,2))\n",
    "\n",
    "#print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E Accuracy for  1  neigbours.\n",
      "Label I-E test score is : 0.6651296829971182\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[  96  300]\n",
      " [ 281 1058]]\n",
      "I-E Accuracy for  3  neigbours.\n",
      "Label I-E test score is : 0.6927953890489914\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[  56  382]\n",
      " [ 151 1146]]\n",
      "I-E Accuracy for  5  neigbours.\n",
      "Label I-E test score is : 0.7446685878962536\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[  34  368]\n",
      " [  75 1258]]\n",
      "I-E Accuracy for  7  neigbours.\n",
      "Label I-E test score is : 0.7544668587896254\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[  24  362]\n",
      " [  64 1285]]\n",
      "I-E Accuracy for  9  neigbours.\n",
      "Label I-E test score is : 0.7463976945244957\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[  12  399]\n",
      " [  41 1283]]\n",
      "I-E Accuracy for  11  neigbours.\n",
      "Label I-E test score is : 0.7619596541786744\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[  11  380]\n",
      " [  33 1311]]\n",
      "I-E Accuracy for  13  neigbours.\n",
      "Label I-E test score is : 0.7487031700288185\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   9  422]\n",
      " [  14 1290]]\n",
      "I-E Accuracy for  15  neigbours.\n",
      "Label I-E test score is : 0.7706051873198847\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   7  384]\n",
      " [  14 1330]]\n",
      "I-E Accuracy for  17  neigbours.\n",
      "Label I-E test score is : 0.7665706051873199\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   7  393]\n",
      " [  12 1323]]\n",
      "I-E Accuracy for  19  neigbours.\n",
      "Label I-E test score is : 0.7590778097982709\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   3  414]\n",
      " [   4 1314]]\n",
      "I-E Accuracy for  21  neigbours.\n",
      "Label I-E test score is : 0.7544668587896254\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   7  419]\n",
      " [   7 1302]]\n",
      "I-E Accuracy for  23  neigbours.\n",
      "Label I-E test score is : 0.777521613832853\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   2  380]\n",
      " [   6 1347]]\n",
      "I-E Accuracy for  25  neigbours.\n",
      "Label I-E test score is : 0.7648414985590778\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   5  406]\n",
      " [   2 1322]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "for x in range(1, 26, 2):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(scaled, y_IE, test_size=0.2)\n",
    "    knn = KNeighborsClassifier(n_neighbors = x)\n",
    "    clf = knn.fit(x_train, y_train)\n",
    "    predknn = clf.predict(x_test)\n",
    "    print(\"I-E Accuracy for \", x, \" neigbours.\")\n",
    "    print('Label I-E test score is :',accuracy_score(y_test, predknn))\n",
    "    print(\"Confusion Matrix for KNeighbors:\")\n",
    "    print(confusion_matrix(y_test, predknn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E Accuracy for  1  max_depth.\n",
      "[[1492    0]\n",
      " [ 243    0]]\n",
      "Score: 85.99\n",
      "I-E Accuracy for  2  max_depth.\n",
      "[[1511    0]\n",
      " [ 224    0]]\n",
      "Score: 87.09\n",
      "I-E Accuracy for  3  max_depth.\n",
      "[[1494    0]\n",
      " [ 241    0]]\n",
      "Score: 86.11\n",
      "I-E Accuracy for  4  max_depth.\n",
      "[[1484    0]\n",
      " [ 251    0]]\n",
      "Score: 85.53\n",
      "I-E Accuracy for  5  max_depth.\n",
      "[[1502    0]\n",
      " [ 233    0]]\n",
      "Score: 86.57\n",
      "I-E Accuracy for  6  max_depth.\n",
      "[[1521    0]\n",
      " [ 214    0]]\n",
      "Score: 87.67\n",
      "I-E Accuracy for  7  max_depth.\n",
      "[[1479    0]\n",
      " [ 256    0]]\n",
      "Score: 85.24\n",
      "I-E Accuracy for  8  max_depth.\n",
      "[[1489    0]\n",
      " [ 246    0]]\n",
      "Score: 85.82\n",
      "I-E Accuracy for  9  max_depth.\n",
      "[[1505    0]\n",
      " [ 230    0]]\n",
      "Score: 86.74\n",
      "I-E Accuracy for  10  max_depth.\n",
      "[[1482    3]\n",
      " [ 250    0]]\n",
      "Score: 85.42\n",
      "I-E Accuracy for  11  max_depth.\n",
      "[[1521    3]\n",
      " [ 210    1]]\n",
      "Score: 87.72\n",
      "I-E Accuracy for  12  max_depth.\n",
      "[[1499    0]\n",
      " [ 235    1]]\n",
      "Score: 86.46\n",
      "I-E Accuracy for  13  max_depth.\n",
      "[[1472    0]\n",
      " [ 263    0]]\n",
      "Score: 84.84\n",
      "I-E Accuracy for  14  max_depth.\n",
      "[[1494    6]\n",
      " [ 234    1]]\n",
      "Score: 86.17\n",
      "I-E Accuracy for  15  max_depth.\n",
      "[[1507    3]\n",
      " [ 225    0]]\n",
      "Score: 86.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "for x in range(1, 16):\n",
    "    rfn = RandomForestClassifier(max_depth= x, random_state=0)\n",
    "\n",
    "    # NS\n",
    "    x_train, x_test, y_train, y_test = train_test_split(reduced, y_NS, test_size=0.2)\n",
    "    rfn.fit(x_train, y_train)\n",
    "#    ieb_train = knn.score(x_train,y_train)\n",
    "#    ieb_test = knn.score (x_train,y_train)\n",
    "    predrfn = rfn.predict(x_test)\n",
    "    print(\"I-E Accuracy for \", x, \" max_depth.\")\n",
    "#    print('Label I-E train score is :',ieb_train)\n",
    "    print(confusion_matrix(y_test,predrfn))\n",
    "    print(\"Score:\",round(accuracy_score(y_test,predrfn)*100,2))\n",
    "    #print(\"Score:\",round(accuracy_score(predknn, y_test)*100,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E Accuracy for  1  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  2  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  3  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  4  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  5  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  6  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  7  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  8  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  9  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  10  max_depth.\n",
      "[[1496    1]\n",
      " [ 238    0]]\n",
      "Score: 86.22\n",
      "I-E Accuracy for  11  max_depth.\n",
      "[[1495    2]\n",
      " [ 238    0]]\n",
      "Score: 86.17\n",
      "I-E Accuracy for  12  max_depth.\n",
      "[[1495    2]\n",
      " [ 236    2]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  13  max_depth.\n",
      "[[1495    2]\n",
      " [ 237    1]]\n",
      "Score: 86.22\n",
      "I-E Accuracy for  14  max_depth.\n",
      "[[1492    5]\n",
      " [ 236    2]]\n",
      "Score: 86.11\n",
      "I-E Accuracy for  15  max_depth.\n",
      "[[1494    3]\n",
      " [ 237    1]]\n",
      "Score: 86.17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "for x in range(1, 16):\n",
    "    rfn = RandomForestClassifier(max_depth= x, random_state=0)\n",
    "\n",
    "    # NS\n",
    "    x_train, x_test, y_train, y_test = train_test_split(scaled, y_NS, test_size=0.2, random_state=10)\n",
    "    rfn.fit(x_train, y_train)\n",
    "#    ieb_train = knn.score(x_train,y_train)\n",
    "#    ieb_test = knn.score (x_train,y_train)\n",
    "    predrfn = rfn.predict(x_test)\n",
    "    print(\"I-E Accuracy for \", x, \" max_depth.\")\n",
    "#    print('Label I-E train score is :',ieb_train)\n",
    "    print(confusion_matrix(y_test,predrfn))\n",
    "    print(\"Score:\",round(accuracy_score(y_test,predrfn)*100,2))\n",
    "    #print(\"Score:\",round(accuracy_score(predknn, y_test)*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E RESULTS\n",
      "Label I-E train score is : 0.7685545467646635\n",
      "Label I-E test score is : 0.7685545467646635\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[   0  393]\n",
      " [   0 1342]]\n",
      "Score: 77.35\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           E       0.00      0.00      0.00       393\n",
      "           I       0.77      1.00      0.87      1342\n",
      "\n",
      "    accuracy                           0.77      1735\n",
      "   macro avg       0.39      0.50      0.44      1735\n",
      "weighted avg       0.60      0.77      0.67      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "N-S RESULTS\n",
      "Label N-S train score is : 0.8617956477878657\n",
      "Label N-S test score is : 0.8617956477878657\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.86      1.00      0.93      1497\n",
      "           S       0.00      0.00      0.00       238\n",
      "\n",
      "    accuracy                           0.86      1735\n",
      "   macro avg       0.43      0.50      0.46      1735\n",
      "weighted avg       0.74      0.86      0.80      1735\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-F Results\n",
      "Label T-F train score is : 0.5379737714368065\n",
      "Label T-F test score is : 0.5379737714368065\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[960   0]\n",
      " [775   0]]\n",
      "Score: 55.33\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           F       0.55      1.00      0.71       960\n",
      "           T       0.00      0.00      0.00       775\n",
      "\n",
      "    accuracy                           0.55      1735\n",
      "   macro avg       0.28      0.50      0.36      1735\n",
      "weighted avg       0.31      0.55      0.39      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "J-P Results\n",
      "Label J-P train score is : 0.603112840466926\n",
      "Label J-P test score is : 0.603112840466926\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[   0  680]\n",
      " [   0 1055]]\n",
      "Score: 60.81\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           J       0.00      0.00      0.00       680\n",
      "           P       0.61      1.00      0.76      1055\n",
      "\n",
      "    accuracy                           0.61      1735\n",
      "   macro avg       0.30      0.50      0.38      1735\n",
      "weighted avg       0.37      0.61      0.46      1735\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# IE\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled, y_IE, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "ieb_train = mnb.score (x_train,y_train)\n",
    "ieb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"I-E RESULTS\")\n",
    "print('Label I-E train score is :',ieb_train)\n",
    "print('Label I-E test score is :',ieb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# NS\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled, y_NS, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "nsb_train = mnb.score (x_train,y_train)\n",
    "nsb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"N-S RESULTS\")\n",
    "print('Label N-S train score is :',nsb_train)\n",
    "print('Label N-S test score is :',nsb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# TF\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled, y_TF, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "tfb_train = mnb.score (x_train,y_train)\n",
    "tfb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"T-F Results\")\n",
    "print('Label T-F train score is :',tfb_train)\n",
    "print('Label T-F test score is :',tfb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# JP\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled, y_JP, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "jpb_train = mnb.score (x_train,y_train)\n",
    "jpb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"J-P Results\")\n",
    "print('Label J-P train score is :',jpb_train)\n",
    "print('Label J-P test score is :',jpb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E RESULTS\n",
      "Label I-E train score is : 1.0\n",
      "Label I-E test score is : 1.0\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[ 121  272]\n",
      " [ 333 1009]]\n",
      "Score: 65.13\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           E       0.27      0.31      0.29       393\n",
      "           I       0.79      0.75      0.77      1342\n",
      "\n",
      "    accuracy                           0.65      1735\n",
      "   macro avg       0.53      0.53      0.53      1735\n",
      "weighted avg       0.67      0.65      0.66      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "N-S RESULTS\n",
      "Label N-S train score is : 1.0\n",
      "Label N-S test score is : 1.0\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[1239  258]\n",
      " [ 196   42]]\n",
      "Score: 73.83\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.86      0.83      0.85      1497\n",
      "           S       0.14      0.18      0.16       238\n",
      "\n",
      "    accuracy                           0.74      1735\n",
      "   macro avg       0.50      0.50      0.50      1735\n",
      "weighted avg       0.76      0.74      0.75      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "T-F Results\n",
      "Label T-F train score is : 1.0\n",
      "Label T-F test score is : 1.0\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[579 381]\n",
      " [373 402]]\n",
      "Score: 56.54\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           F       0.61      0.60      0.61       960\n",
      "           T       0.51      0.52      0.52       775\n",
      "\n",
      "    accuracy                           0.57      1735\n",
      "   macro avg       0.56      0.56      0.56      1735\n",
      "weighted avg       0.57      0.57      0.57      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "J-P Results\n",
      "Label J-P train score is : 1.0\n",
      "Label J-P test score is : 1.0\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[306 374]\n",
      " [438 617]]\n",
      "Score: 53.2\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           J       0.41      0.45      0.43       680\n",
      "           P       0.62      0.58      0.60      1055\n",
      "\n",
      "    accuracy                           0.53      1735\n",
      "   macro avg       0.52      0.52      0.52      1735\n",
      "weighted avg       0.54      0.53      0.54      1735\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# IE\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_IE, test_size=0.2, random_state=10)\n",
    "dt.fit(x_train, y_train)\n",
    "ieb_train = dt.score (x_train,y_train)\n",
    "ieb_test = dt.score (x_train,y_train)\n",
    "preddt = dt.predict(x_test)\n",
    "print(\"I-E RESULTS\")\n",
    "print('Label I-E train score is :',ieb_train)\n",
    "print('Label I-E test score is :',ieb_test)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# NS\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_NS, test_size=0.2, random_state=10)\n",
    "dt.fit(x_train, y_train)\n",
    "nsb_train = dt.score (x_train,y_train)\n",
    "nsb_test = dt.score (x_train,y_train)\n",
    "preddt = dt.predict(x_test)\n",
    "print(\"N-S RESULTS\")\n",
    "print('Label N-S train score is :',nsb_train)\n",
    "print('Label N-S test score is :',nsb_test)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# TF\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_TF, test_size=0.2, random_state=10)\n",
    "dt.fit(x_train, y_train)\n",
    "tfb_train = dt.score (x_train,y_train)\n",
    "tfb_test = dt.score (x_train,y_train)\n",
    "preddt = dt.predict(x_test)\n",
    "print(\"T-F Results\")\n",
    "print('Label T-F train score is :',tfb_train)\n",
    "print('Label T-F test score is :',tfb_test)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# JP\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_JP, test_size=0.2, random_state=10)\n",
    "dt.fit(x_train, y_train)\n",
    "jpb_train = dt.score (x_train,y_train)\n",
    "jpb_test = dt.score (x_train,y_train)\n",
    "preddt = dt.predict(x_test)\n",
    "print(\"J-P Results\")\n",
    "print('Label J-P train score is :',jpb_train)\n",
    "print('Label J-P test score is :',jpb_test)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E RESULTS\n",
      "Label I-E train score is : 1.0\n",
      "Label I-E test score is : 1.0\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[116 277]\n",
      " [357 985]]\n",
      "Score: 63.46\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           E       0.25      0.30      0.27       393\n",
      "           I       0.78      0.73      0.76      1342\n",
      "\n",
      "    accuracy                           0.63      1735\n",
      "   macro avg       0.51      0.51      0.51      1735\n",
      "weighted avg       0.66      0.63      0.65      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "N-S RESULTS\n",
      "Label N-S train score is : 1.0\n",
      "Label N-S test score is : 1.0\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[1253  244]\n",
      " [ 198   40]]\n",
      "Score: 74.52\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.86      0.84      0.85      1497\n",
      "           S       0.14      0.17      0.15       238\n",
      "\n",
      "    accuracy                           0.75      1735\n",
      "   macro avg       0.50      0.50      0.50      1735\n",
      "weighted avg       0.76      0.75      0.75      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "T-F Results\n",
      "Label T-F train score is : 1.0\n",
      "Label T-F test score is : 1.0\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[589 371]\n",
      " [357 418]]\n",
      "Score: 58.04\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           F       0.62      0.61      0.62       960\n",
      "           T       0.53      0.54      0.53       775\n",
      "\n",
      "    accuracy                           0.58      1735\n",
      "   macro avg       0.58      0.58      0.58      1735\n",
      "weighted avg       0.58      0.58      0.58      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "J-P Results\n",
      "Label J-P train score is : 1.0\n",
      "Label J-P test score is : 1.0\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[309 371]\n",
      " [432 623]]\n",
      "Score: 53.72\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           J       0.42      0.45      0.43       680\n",
      "           P       0.63      0.59      0.61      1055\n",
      "\n",
      "    accuracy                           0.54      1735\n",
      "   macro avg       0.52      0.52      0.52      1735\n",
      "weighted avg       0.54      0.54      0.54      1735\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# IE\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled, y_IE, test_size=0.2, random_state=10)\n",
    "dt.fit(x_train, y_train)\n",
    "ieb_train = dt.score (x_train,y_train)\n",
    "ieb_test = dt.score (x_train,y_train)\n",
    "preddt = dt.predict(x_test)\n",
    "print(\"I-E RESULTS\")\n",
    "print('Label I-E train score is :',ieb_train)\n",
    "print('Label I-E test score is :',ieb_test)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# NS\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled, y_NS, test_size=0.2, random_state=10)\n",
    "dt.fit(x_train, y_train)\n",
    "nsb_train = dt.score (x_train,y_train)\n",
    "nsb_test = dt.score (x_train,y_train)\n",
    "preddt = dt.predict(x_test)\n",
    "print(\"N-S RESULTS\")\n",
    "print('Label N-S train score is :',nsb_train)\n",
    "print('Label N-S test score is :',nsb_test)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# TF\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled, y_TF, test_size=0.2, random_state=10)\n",
    "dt.fit(x_train, y_train)\n",
    "tfb_train = dt.score (x_train,y_train)\n",
    "tfb_test = dt.score (x_train,y_train)\n",
    "preddt = dt.predict(x_test)\n",
    "print(\"T-F Results\")\n",
    "print('Label T-F train score is :',tfb_train)\n",
    "print('Label T-F test score is :',tfb_test)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# JP\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled, y_JP, test_size=0.2, random_state=10)\n",
    "dt.fit(x_train, y_train)\n",
    "jpb_train = dt.score (x_train,y_train)\n",
    "jpb_test = dt.score (x_train,y_train)\n",
    "preddt = dt.predict(x_test)\n",
    "print(\"J-P Results\")\n",
    "print('Label J-P train score is :',jpb_train)\n",
    "print('Label J-P test score is :',jpb_test)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E RESULTS\n",
      "Label I-E train score is : 0.7867127828217323\n",
      "Label I-E test score is : 0.7867127828217323\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[  39  354]\n",
      " [  58 1284]]\n",
      "Score: 76.25\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           E       0.40      0.10      0.16       393\n",
      "           I       0.78      0.96      0.86      1342\n",
      "\n",
      "    accuracy                           0.76      1735\n",
      "   macro avg       0.59      0.53      0.51      1735\n",
      "weighted avg       0.70      0.76      0.70      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "N-S RESULTS\n",
      "Label N-S train score is : 0.8648220204640438\n",
      "Label N-S test score is : 0.8648220204640438\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[1475   22]\n",
      " [ 233    5]]\n",
      "Score: 85.3\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.86      0.99      0.92      1497\n",
      "           S       0.19      0.02      0.04       238\n",
      "\n",
      "    accuracy                           0.85      1735\n",
      "   macro avg       0.52      0.50      0.48      1735\n",
      "weighted avg       0.77      0.85      0.80      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "T-F Results\n",
      "Label T-F train score is : 0.7122063697939184\n",
      "Label T-F test score is : 0.7122063697939184\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[509 451]\n",
      " [282 493]]\n",
      "Score: 57.75\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           F       0.64      0.53      0.58       960\n",
      "           T       0.52      0.64      0.57       775\n",
      "\n",
      "    accuracy                           0.58      1735\n",
      "   macro avg       0.58      0.58      0.58      1735\n",
      "weighted avg       0.59      0.58      0.58      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "J-P Results\n",
      "Label J-P train score is : 0.6921746649373108\n",
      "Label J-P test score is : 0.6921746649373108\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[196 484]\n",
      " [282 773]]\n",
      "Score: 55.85\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           J       0.41      0.29      0.34       680\n",
      "           P       0.61      0.73      0.67      1055\n",
      "\n",
      "    accuracy                           0.56      1735\n",
      "   macro avg       0.51      0.51      0.50      1735\n",
      "weighted avg       0.53      0.56      0.54      1735\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "\n",
    "\n",
    "# IE\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_IE, test_size=0.2, random_state=10)\n",
    "knn.fit(x_train, y_train)\n",
    "ieb_train = knn.score (x_train,y_train)\n",
    "ieb_test = knn.score (x_train,y_train)\n",
    "predknn = knn.predict(x_test)\n",
    "print(\"I-E RESULTS\")\n",
    "print('Label I-E train score is :',ieb_train)\n",
    "print('Label I-E test score is :',ieb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predknn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# NS\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_NS, test_size=0.2, random_state=10)\n",
    "knn.fit(x_train, y_train)\n",
    "nsb_train = knn.score (x_train,y_train)\n",
    "nsb_test = knn.score (x_train,y_train)\n",
    "predknn = knn.predict(x_test)\n",
    "print(\"N-S RESULTS\")\n",
    "print('Label N-S train score is :',nsb_train)\n",
    "print('Label N-S test score is :',nsb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predknn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# TF\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_TF, test_size=0.2, random_state=10)\n",
    "knn.fit(x_train, y_train)\n",
    "tfb_train = knn.score (x_train,y_train)\n",
    "tfb_test = knn.score (x_train,y_train)\n",
    "predknn = knn.predict(x_test)\n",
    "print(\"T-F Results\")\n",
    "print('Label T-F train score is :',tfb_train)\n",
    "print('Label T-F test score is :',tfb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predknn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# JP\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_JP, test_size=0.2, random_state=10)\n",
    "knn.fit(x_train, y_train)\n",
    "jpb_train = knn.score (x_train,y_train)\n",
    "jpb_test = knn.score (x_train,y_train)\n",
    "predknn = knn.predict(x_test)\n",
    "print(\"J-P Results\")\n",
    "print('Label J-P train score is :',jpb_train)\n",
    "print('Label J-P test score is :',jpb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predknn))\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E RESULTS\n",
      "Label I-E train score is : 0.788586251621271\n",
      "Label I-E test score is : 0.788586251621271\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[  27  366]\n",
      " [  73 1269]]\n",
      "Score: 74.7\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           E       0.27      0.07      0.11       393\n",
      "           I       0.78      0.95      0.85      1342\n",
      "\n",
      "    accuracy                           0.75      1735\n",
      "   macro avg       0.52      0.51      0.48      1735\n",
      "weighted avg       0.66      0.75      0.68      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "N-S RESULTS\n",
      "Label N-S train score is : 0.8642455685257242\n",
      "Label N-S test score is : 0.8642455685257242\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[1479   18]\n",
      " [ 234    4]]\n",
      "Score: 85.48\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.86      0.99      0.92      1497\n",
      "           S       0.18      0.02      0.03       238\n",
      "\n",
      "    accuracy                           0.85      1735\n",
      "   macro avg       0.52      0.50      0.48      1735\n",
      "weighted avg       0.77      0.85      0.80      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "T-F Results\n",
      "Label T-F train score is : 0.7114858048710189\n",
      "Label T-F test score is : 0.7114858048710189\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[510 450]\n",
      " [295 480]]\n",
      "Score: 57.06\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           F       0.63      0.53      0.58       960\n",
      "           T       0.52      0.62      0.56       775\n",
      "\n",
      "    accuracy                           0.57      1735\n",
      "   macro avg       0.57      0.58      0.57      1735\n",
      "weighted avg       0.58      0.57      0.57      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "J-P Results\n",
      "Label J-P train score is : 0.6931834558293702\n",
      "Label J-P test score is : 0.6931834558293702\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[201 479]\n",
      " [286 769]]\n",
      "Score: 55.91\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           J       0.41      0.30      0.34       680\n",
      "           P       0.62      0.73      0.67      1055\n",
      "\n",
      "    accuracy                           0.56      1735\n",
      "   macro avg       0.51      0.51      0.51      1735\n",
      "weighted avg       0.54      0.56      0.54      1735\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "\n",
    "\n",
    "# IE\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_IE, test_size=0.2, random_state=10)\n",
    "knn.fit(x_train, y_train)\n",
    "ieb_train = knn.score (x_train,y_train)\n",
    "ieb_test = knn.score (x_train,y_train)\n",
    "predknn = knn.predict(x_test)\n",
    "print(\"I-E RESULTS\")\n",
    "print('Label I-E train score is :',ieb_train)\n",
    "print('Label I-E test score is :',ieb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predknn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# NS\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_NS, test_size=0.2, random_state=10)\n",
    "knn.fit(x_train, y_train)\n",
    "nsb_train = knn.score (x_train,y_train)\n",
    "nsb_test = knn.score (x_train,y_train)\n",
    "predknn = knn.predict(x_test)\n",
    "print(\"N-S RESULTS\")\n",
    "print('Label N-S train score is :',nsb_train)\n",
    "print('Label N-S test score is :',nsb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predknn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# TF\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_TF, test_size=0.2, random_state=10)\n",
    "knn.fit(x_train, y_train)\n",
    "tfb_train = knn.score (x_train,y_train)\n",
    "tfb_test = knn.score (x_train,y_train)\n",
    "predknn = knn.predict(x_test)\n",
    "print(\"T-F Results\")\n",
    "print('Label T-F train score is :',tfb_train)\n",
    "print('Label T-F test score is :',tfb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predknn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# JP\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_JP, test_size=0.2, random_state=10)\n",
    "knn.fit(x_train, y_train)\n",
    "jpb_train = knn.score (x_train,y_train)\n",
    "jpb_test = knn.score (x_train,y_train)\n",
    "predknn = knn.predict(x_test)\n",
    "print(\"J-P Results\")\n",
    "print('Label J-P train score is :',jpb_train)\n",
    "print('Label J-P test score is :',jpb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predknn))\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E RESULTS\n",
      "Label I-E train score is : 0.7691309987029832\n",
      "Label I-E test score is : 0.7691309987029832\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[   0  393]\n",
      " [   0 1342]]\n",
      "Score: 77.35\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           E       0.00      0.00      0.00       393\n",
      "           I       0.77      1.00      0.87      1342\n",
      "\n",
      "    accuracy                           0.77      1735\n",
      "   macro avg       0.39      0.50      0.44      1735\n",
      "weighted avg       0.60      0.77      0.67      1735\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-S RESULTS\n",
      "Label N-S train score is : 0.8619397607724456\n",
      "Label N-S test score is : 0.8619397607724456\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.86      1.00      0.93      1497\n",
      "           S       0.00      0.00      0.00       238\n",
      "\n",
      "    accuracy                           0.86      1735\n",
      "   macro avg       0.43      0.50      0.46      1735\n",
      "weighted avg       0.74      0.86      0.80      1735\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-F Results\n",
      "Label T-F train score is : 0.7169620982850555\n",
      "Label T-F test score is : 0.7169620982850555\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[725 235]\n",
      " [369 406]]\n",
      "Score: 65.19\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           F       0.66      0.76      0.71       960\n",
      "           T       0.63      0.52      0.57       775\n",
      "\n",
      "    accuracy                           0.65      1735\n",
      "   macro avg       0.65      0.64      0.64      1735\n",
      "weighted avg       0.65      0.65      0.65      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "J-P Results\n",
      "Label J-P train score is : 0.6281884997838305\n",
      "Label J-P test score is : 0.6281884997838305\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[  11  669]\n",
      " [   4 1051]]\n",
      "Score: 61.21\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           J       0.73      0.02      0.03       680\n",
      "           P       0.61      1.00      0.76      1055\n",
      "\n",
      "    accuracy                           0.61      1735\n",
      "   macro avg       0.67      0.51      0.39      1735\n",
      "weighted avg       0.66      0.61      0.47      1735\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfn = RandomForestClassifier(max_depth=5, random_state=0)\n",
    "rfn.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# IE\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled, y_IE, test_size=0.2, random_state=10)\n",
    "rfn.fit(x_train, y_train)\n",
    "ieb_train = rfn.score (x_train,y_train)\n",
    "ieb_test = rfn.score (x_train,y_train)\n",
    "predrfn = rfn.predict(x_test)\n",
    "print(\"I-E RESULTS\")\n",
    "print('Label I-E train score is :',ieb_train)\n",
    "print('Label I-E test score is :',ieb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predrfn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predrfn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predrfn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# NS\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled, y_NS, test_size=0.2, random_state=10)\n",
    "rfn.fit(x_train, y_train)\n",
    "nsb_train = rfn.score (x_train,y_train)\n",
    "nsb_test = rfn.score (x_train,y_train)\n",
    "predrfn = rfn.predict(x_test)\n",
    "print(\"N-S RESULTS\")\n",
    "print('Label N-S train score is :',nsb_train)\n",
    "print('Label N-S test score is :',nsb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predrfn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predrfn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predrfn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# TF\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled, y_TF, test_size=0.2, random_state=10)\n",
    "rfn.fit(x_train, y_train)\n",
    "tfb_train = rfn.score (x_train,y_train)\n",
    "tfb_test = rfn.score (x_train,y_train)\n",
    "predrfn = rfn.predict(x_test)\n",
    "print(\"T-F Results\")\n",
    "print('Label T-F train score is :',tfb_train)\n",
    "print('Label T-F test score is :',tfb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predrfn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predrfn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predrfn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# JP\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled, y_JP, test_size=0.2, random_state=10)\n",
    "rfn.fit(x_train, y_train)\n",
    "jpb_train = rfn.score (x_train,y_train)\n",
    "jpb_test = rfn.score (x_train,y_train)\n",
    "predrfn = rfn.predict(x_test)\n",
    "print(\"J-P Results\")\n",
    "print('Label J-P train score is :',jpb_train)\n",
    "print('Label J-P test score is :',jpb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predrfn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predrfn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predrfn))\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text_ready</th>\n",
       "      <th>I-E</th>\n",
       "      <th>N-S</th>\n",
       "      <th>T-F</th>\n",
       "      <th>J-P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>intj moment sportscent top ten play prank ha l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>find lack post veri alarm sex bore posit often...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one cours say know bless cur doe absolut ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp enjoy convers day esoter gab natur u...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fire anoth silli misconcept approach logic go ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>becaus alway think cat fi dom reason websit be...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>thi thread alreadi exist someplac el doe heck ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>mani question thing would take purpl pill pick...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>veri conflict right come want child honestli m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>ha long sinc personalitycaf although seem chan...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8674 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                         text_ready  I-E  N-S  T-F  \\\n",
       "0     INFJ  intj moment sportscent top ten play prank ha l...    1    0    0   \n",
       "1     ENTP  find lack post veri alarm sex bore posit often...    0    0    1   \n",
       "2     INTP  good one cours say know bless cur doe absolut ...    1    0    1   \n",
       "3     INTJ  dear intp enjoy convers day esoter gab natur u...    1    0    1   \n",
       "4     ENTJ  fire anoth silli misconcept approach logic go ...    0    0    1   \n",
       "...    ...                                                ...  ...  ...  ...   \n",
       "8670  ISFP  becaus alway think cat fi dom reason websit be...    1    1    0   \n",
       "8671  ENFP  thi thread alreadi exist someplac el doe heck ...    0    0    0   \n",
       "8672  INTP  mani question thing would take purpl pill pick...    1    0    1   \n",
       "8673  INFP  veri conflict right come want child honestli m...    1    0    0   \n",
       "8674  INFP  ha long sinc personalitycaf although seem chan...    1    0    0   \n",
       "\n",
       "      J-P  \n",
       "0       0  \n",
       "1       1  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  \n",
       "...   ...  \n",
       "8670    1  \n",
       "8671    1  \n",
       "8672    1  \n",
       "8673    1  \n",
       "8674    1  \n",
       "\n",
       "[8674 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_neural = data2.copy()\n",
    "\n",
    "data_neural['I-E'] = data_neural['I-E'].astype('category')\n",
    "data_neural['N-S'] = data_neural['N-S'].astype('category')\n",
    "data_neural['T-F'] = data_neural['T-F'].astype('category')\n",
    "data_neural['J-P'] = data_neural['J-P'].astype('category')\n",
    "\n",
    "cat_columns = data_neural.select_dtypes(['category']).columns\n",
    "\n",
    "data_neural[cat_columns] = data_neural[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "data_neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = data_neural['text_ready']\n",
    "\n",
    "y_IE = data_neural['I-E']\n",
    "y_NS = data_neural['N-S']\n",
    "y_TF = data_neural['T-F']\n",
    "y_JP = data_neural['J-P']\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vector = CountVectorizer(ngram_range=(2, 2)).fit(x) \n",
    "X = vector.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=256, kernel_initializer='uniform', activation='relu', input_dim=1986297))\n",
    "model.add(tf.keras.layers.Dense(units=128, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=64, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(activation = 'sigmoid', units = 1, kernel_initializer = 'uniform')) # output layer has number of outputs not number of neurons\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# calculating loss, model is always trying to minimize loss, adam is the default optimize\n",
    "\n",
    "\n",
    "# model.fit(X_train, y_train, epochs = 10, batch_size= 25)\n",
    "\n",
    "# val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print(f'Test loss: {val_loss}')\n",
    "# print(f'Test accuracy: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6939, 1986297)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " TypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 241, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 130, in __call__\n    ret = self._func(*args)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 309, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 513, in py_method\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 513, in <listcomp>\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 512, in slice_array\n    contiguous=contiguous)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 391, in slice_arrays\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 391, in <listcomp>\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 391, in <listcomp>\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_2113]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a0e8df9636ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# IE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_IE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I-E RESULTS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  TypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 241, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 130, in __call__\n    ret = self._func(*args)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 309, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 513, in py_method\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 513, in <listcomp>\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 512, in slice_array\n    contiguous=contiguous)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 391, in slice_arrays\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 391, in <listcomp>\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 391, in <listcomp>\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_2113]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# IE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_IE, test_size=0.2, random_state=10)\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size= 25)\n",
    "predmodel = model.predict(x_test)\n",
    "print(\"I-E RESULTS\")\n",
    "# print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "# print(confusion_matrix(y_test,predmodel))\n",
    "# print(\"Score:\",round(accuracy_score(y_test,predmodel)*100,2))\n",
    "# print(\"Classification Report:\",classification_report(y_test,predmodel))\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {val_loss}')\n",
    "print(f'Test accuracy: {val_acc}')\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# NS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_NS, test_size=0.2, random_state=10)\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size= 25)\n",
    "predmodel = model.predict(x_test)\n",
    "print(\"N-S RESULTS\")\n",
    "# print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "# print(confusion_matrix(y_test,predmodel))\n",
    "# print(\"Score:\",round(accuracy_score(y_test,predmodel)*100,2))\n",
    "# print(\"Classification Report:\",classification_report(y_test,predmodel))\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {val_loss}')\n",
    "print(f'Test accuracy: {val_acc}')\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# TF\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_TF, test_size=0.2, random_state=10)\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size= 25)\n",
    "predmodel = model.predict(x_test)\n",
    "print(\"T-F Results\")\n",
    "# print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "# print(confusion_matrix(y_test,predmodel))\n",
    "# print(\"Score:\",round(accuracy_score(y_test,predmodel)*100,2))\n",
    "# print(\"Classification Report:\",classification_report(y_test,predmodel))\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {val_loss}')\n",
    "print(f'Test accuracy: {val_acc}')\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# JP\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_JP, test_size=0.2, random_state=10)\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size= 25)\n",
    "predmodel = model.predict(x_test)\n",
    "print(\"J-P Results\")\n",
    "# print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "# print(confusion_matrix(y_test,predmodel))\n",
    "# print(\"Score:\",round(accuracy_score(y_test,predmodel)*100,2))\n",
    "# print(\"Classification Report:\",classification_report(y_test,predmodel))\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {val_loss}')\n",
    "print(f'Test accuracy: {val_acc}')\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# IE\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_IE, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "ieb_train = mnb.score (x_train,y_train)\n",
    "ieb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"I-E RESULTS\")\n",
    "print('Label I-E train score is :',ieb_train)\n",
    "print('Label I-E test score is :',ieb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# NS\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_NS, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "nsb_train = mnb.score (x_train,y_train)\n",
    "nsb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"N-S RESULTS\")\n",
    "print('Label N-S train score is :',nsb_train)\n",
    "print('Label N-S test score is :',nsb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# TF\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_TF, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "tfb_train = mnb.score (x_train,y_train)\n",
    "tfb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"T-F Results\")\n",
    "print('Label T-F train score is :',tfb_train)\n",
    "print('Label T-F test score is :',tfb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# JP\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_JP, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "jpb_train = mnb.score (x_train,y_train)\n",
    "jpb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"J-P Results\")\n",
    "print('Label J-P train score is :',jpb_train)\n",
    "print('Label J-P test score is :',jpb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
