{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Ultimate Tool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import click\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def save_captions(prefix, user, caption_all):\n",
    "    \"\"\"\n",
    "    Write a list of captions to files (one file per caption).\n",
    "    :param prefix: The directory in which the files will be saved\n",
    "    :param prefix: str\n",
    "    :param user: Username of the account the posts' captions come from\n",
    "    (will be used as a prefix in the filenames)\n",
    "    :param user: str\n",
    "    :param caption_all: A list of captions\n",
    "    :param caption_all: list<str>\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    for idx, caption in enumerate(caption_all):\n",
    "        filename = '{0}_{1}.txt'.format(user, idx)\n",
    "        filename = os.path.join(prefix, filename)\n",
    "        print('saving caption {0}'.format(filename))\n",
    "        text_file = open(filename, 'w')\n",
    "        text_file.write(caption)\n",
    "        text_file.close()\n",
    "\n",
    "\n",
    "def download_and_save_images(prefix, user, img_url_all):\n",
    "    \"\"\"\n",
    "    Download and save a list of images from their urls.\n",
    "    :param prefix: The directory in which the images will be saved\n",
    "    :param prefix: str\n",
    "    :param user: Username of the account the posts' images come from\n",
    "    (will be used as a prefix in the filenames)\n",
    "    :param user: str\n",
    "    :param img_url_all: A list of image urls\n",
    "    :param img_url_all: list<str>\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    for idx, img_url in enumerate(img_url_all):\n",
    "        img_data = requests.get(img_url, verify=False).content\n",
    "        filename = '{0}_{1}.jpg'.format(user, idx)\n",
    "        filename = os.path.join(prefix, filename)\n",
    "        print('saving image {0}'.format(filename))\n",
    "        with open(filename, 'wb') as handler:\n",
    "            handler.write(img_data)\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option('--images/--no-images', default=True,\n",
    "              help='Scrap also images.')\n",
    "@click.option('--captions/--no-captions', default=True,\n",
    "              help='Scrap also captions.')\n",
    "@click.option('--user', '-u', required=True,\n",
    "              help='The account to scrap.')\n",
    "@click.option('--number', '-n', default=10,\n",
    "              help='Number of posts to scrap. (newer posts are scraped first).')\n",
    "def scrap(images, captions, user, number):\n",
    "    \"\"\"\n",
    "    Scrap photos and captions from posts of a single user.\n",
    "    :param images: Include images in the data scraped\n",
    "    :param images: boolean\n",
    "    :param captions: Include captions in the data scraped\n",
    "    :param captions: boolean\n",
    "    :param user: The account to scrap\n",
    "    :param user: str\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    BASE_URL = 'https://deskgram.org'\n",
    "    SIG = \"?_nc_ht=scontent-dfw5-1.cdninstagram.com\"\n",
    "    USER = user\n",
    "    PATTERN_FOR_IMAGES = {'name': \"div\", 'attrs': {\"class\": \"post-img\"}}\n",
    "    PATTERN_FOR_CAPTIONS = {'name': \"div\", 'attrs': {\"class\": \"post-caption\"}}\n",
    "    DEST_FOLDER = './{0}'.format(USER)\n",
    "\n",
    "    url = BASE_URL + '/' + USER\n",
    "    img_url_all = list() if images else None\n",
    "    caption_all = list() if captions else None\n",
    "\n",
    "    if not os.path.exists(DEST_FOLDER):\n",
    "        os.makedirs(DEST_FOLDER)\n",
    "\n",
    "    while True:\n",
    "        print('fetching {0}'.format(url))\n",
    "        r = requests.get(url, verify=False)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "        if images:\n",
    "            images = soup.findAll(**PATTERN_FOR_IMAGES)\n",
    "            for image in images:\n",
    "                img_url = image.img['src'].split('?')[0]\n",
    "                img_url += SIG\n",
    "                img_url_all.append(img_url)\n",
    "                if len(img_url_all) == number and not captions:\n",
    "                    break\n",
    "            print('Found {0} images.'.format(len(images)))\n",
    "            if len(img_url_all) == number and not captions:\n",
    "                break\n",
    "\n",
    "        if captions:\n",
    "            captions = soup.findAll(**PATTERN_FOR_CAPTIONS)\n",
    "            for caption in captions:\n",
    "                caption_all.append(caption.text)\n",
    "                print(len(caption_all))\n",
    "                if len(caption_all) == number:\n",
    "                    break\n",
    "            print('Found {0} captions.'.format(len(captions)))\n",
    "            if len(caption_all) == number:\n",
    "                break\n",
    "\n",
    "        links = soup.findAll('a')\n",
    "        next_link = list(filter(lambda x: 'next_id' in x['href'], links))\n",
    "        if len(next_link) == 0:\n",
    "            break\n",
    "        else:\n",
    "            dest = next_link[0]['href']\n",
    "            url = BASE_URL + dest\n",
    "\n",
    "    if images:\n",
    "        download_and_save_images(DEST_FOLDER, USER, img_url_all)\n",
    "\n",
    "    if captions:\n",
    "        save_captions(DEST_FOLDER, USER, caption_all)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    scrap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Captions & Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
